{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), _ = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(x_train[10]))\n",
    "plt.show()\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def generator(z, y, reuse=False, verbose=True):\\n    \\n    with tf.variable_scope(\"generator\", reuse=reuse):\\n        # Concatenate noise and conditional one-hot variable\\n        inputs = tf.concat([z, y], 1)\\n\\n        # FC layer\\n        fc1 = tf.layers.dense(inputs=inputs, units= 7 * 7 * 128, activation=tf.nn.leaky_relu)\\n\\n        reshaped = tf.reshape(fc1, shape=[-1, 7, 7, 128])\\n\\n        upconv1 = tf.layers.conv2d_transpose(inputs=reshaped,\\n                                            filters=32,\\n                                            kernel_size=[5,5],\\n                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\\n                                            strides=[2,2],\\n                                            activation=tf.nn.leaky_relu,\\n                                            padding=\\'same\\', \\n                                            name=\\'upscore1\\')\\n        \\n        upconv2 = tf.layers.conv2d_transpose(inputs=upconv1,\\n                                            filters=1,\\n                                            kernel_size=[3,3],\\n                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\\n                                            strides=[2,2],\\n                                            activation=None,\\n                                            padding=\\'same\\', \\n                                            name=\\'upscore2\\')\\n        \\n        prob = tf.nn.sigmoid(upconv2)\\n        \\n        if verbose:\\n            print(\"\\nGenerator:\")\\n            print(inputs)\\n            print(fc1)\\n            print(reshaped)\\n            print(upconv1)\\n            print(upconv2)\\n    \\n    return prob\\n\\n\\ndef discriminator(x, y, reuse=False, verbose=True):\\n    \\n    with tf.variable_scope(\"discriminator\", reuse=reuse):      \\n        \\n        conv1 = tf.layers.conv2d(inputs=x, \\n                                filters=64, \\n                                kernel_size=[5,5], \\n                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\\n                                strides=[1,1], \\n                                activation=tf.nn.leaky_relu, \\n                                padding=\\'same\\', \\n                                name=\\'Conv1\\')\\n        \\n        pool1 = tf.layers.max_pooling2d(inputs=conv1, \\n                                        pool_size=[2,2], \\n                                        strides=[2,2], \\n                                        padding=\\'same\\', \\n                                        name=\\'Pool1\\')\\n        \\n        \\n        conv2 = tf.layers.conv2d(inputs=pool1, \\n                                filters=32, \\n                                kernel_size=[3,3], \\n                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\\n                                strides=[2,2], \\n                                activation=tf.nn.leaky_relu,  \\n                                padding=\\'same\\', \\n                                name=\\'Conv2\\')\\n        \\n        pool2 = tf.layers.max_pooling2d(inputs=conv2, \\n                                        pool_size=[2,2], \\n                                        strides=[2,2], \\n                                        padding=\\'same\\', \\n                                        name=\\'Pool2\\')\\n\\n        flattened = tf.layers.flatten(pool2)\\n        concatened = tf.concat([flattened, y], 1)\\n        fc1 = tf.layers.dense(inputs=concatened, units=256, activation=tf.nn.leaky_relu)\\n        fc2 = tf.layers.dense(inputs=fc1, units=1, activation=None)\\n        prob = tf.nn.sigmoid(fc2)\\n        \\n        if verbose:\\n            print(\"\\nDiscriminator:\")\\n            print(conv1)\\n            print(pool1)\\n            print(conv2)\\n            print(pool2)\\n            print(flattened)\\n            print(concatened)\\n            print(fc1)\\n            print(fc2)\\n        \\n    return prob, fc2\\n\\n\\ndef sample_Z(batch_size, img_size):\\n    # Sample noise for generator\\n    return np.random.uniform(-1., 1., size=[batch_size, img_size])\\n\\n\\ndef one_hot(batch_size, num_classes, labels):\\n    assert(batch_size == len(labels))\\n    y_one_hot = np.zeros(shape=[batch_size, num_classes])\\n    y_one_hot[np.arange(batch_size), labels] = 1\\n    \\n    return y_one_hot'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def generator(z, y, reuse=False, verbose=True):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Concatenate noise and conditional one-hot variable\n",
    "        inputs = tf.concat([z, y], 1)\n",
    "\n",
    "        # FC layer\n",
    "        fc1 = tf.layers.dense(inputs=inputs, units= 7 * 7 * 128, activation=tf.nn.leaky_relu)\n",
    "\n",
    "        reshaped = tf.reshape(fc1, shape=[-1, 7, 7, 128])\n",
    "\n",
    "        upconv1 = tf.layers.conv2d_transpose(inputs=reshaped,\n",
    "                                            filters=32,\n",
    "                                            kernel_size=[5,5],\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                            strides=[2,2],\n",
    "                                            activation=tf.nn.leaky_relu,\n",
    "                                            padding='same', \n",
    "                                            name='upscore1')\n",
    "        \n",
    "        upconv2 = tf.layers.conv2d_transpose(inputs=upconv1,\n",
    "                                            filters=1,\n",
    "                                            kernel_size=[3,3],\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                            strides=[2,2],\n",
    "                                            activation=None,\n",
    "                                            padding='same', \n",
    "                                            name='upscore2')\n",
    "        \n",
    "        prob = tf.nn.sigmoid(upconv2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nGenerator:\")\n",
    "            print(inputs)\n",
    "            print(fc1)\n",
    "            print(reshaped)\n",
    "            print(upconv1)\n",
    "            print(upconv2)\n",
    "    \n",
    "    return prob\n",
    "\n",
    "\n",
    "def discriminator(x, y, reuse=False, verbose=True):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):      \n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs=x, \n",
    "                                filters=64, \n",
    "                                kernel_size=[5,5], \n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                strides=[1,1], \n",
    "                                activation=tf.nn.leaky_relu, \n",
    "                                padding='same', \n",
    "                                name='Conv1')\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                        pool_size=[2,2], \n",
    "                                        strides=[2,2], \n",
    "                                        padding='same', \n",
    "                                        name='Pool1')\n",
    "        \n",
    "        \n",
    "        conv2 = tf.layers.conv2d(inputs=pool1, \n",
    "                                filters=32, \n",
    "                                kernel_size=[3,3], \n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                strides=[2,2], \n",
    "                                activation=tf.nn.leaky_relu,  \n",
    "                                padding='same', \n",
    "                                name='Conv2')\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                        pool_size=[2,2], \n",
    "                                        strides=[2,2], \n",
    "                                        padding='same', \n",
    "                                        name='Pool2')\n",
    "\n",
    "        flattened = tf.layers.flatten(pool2)\n",
    "        concatened = tf.concat([flattened, y], 1)\n",
    "        fc1 = tf.layers.dense(inputs=concatened, units=256, activation=tf.nn.leaky_relu)\n",
    "        fc2 = tf.layers.dense(inputs=fc1, units=1, activation=None)\n",
    "        prob = tf.nn.sigmoid(fc2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nDiscriminator:\")\n",
    "            print(conv1)\n",
    "            print(pool1)\n",
    "            print(conv2)\n",
    "            print(pool2)\n",
    "            print(flattened)\n",
    "            print(concatened)\n",
    "            print(fc1)\n",
    "            print(fc2)\n",
    "        \n",
    "    return prob, fc2\n",
    "\n",
    "\n",
    "def sample_Z(batch_size, img_size):\n",
    "    # Sample noise for generator\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, img_size])\n",
    "\n",
    "\n",
    "def one_hot(batch_size, num_classes, labels):\n",
    "    assert(batch_size == len(labels))\n",
    "    y_one_hot = np.zeros(shape=[batch_size, num_classes])\n",
    "    y_one_hot[np.arange(batch_size), labels] = 1\n",
    "    \n",
    "    return y_one_hot'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, y, reuse=False, verbose=True):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        inputs = tf.concat([z, y], 1)\n",
    "        \n",
    "        fc1 = tf.layers.dense(inputs=inputs, units=128, activation=tf.nn.leaky_relu)\n",
    "        fc2 = tf.layers.dense(inputs=fc1, units=784, activation=None)\n",
    "        logits = tf.nn.sigmoid(fc2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nGenerator:\")\n",
    "            print(inputs)\n",
    "            print(fc1)\n",
    "            print(fc2)\n",
    "        \n",
    "    return logits\n",
    "\n",
    "\n",
    "def discriminator(x, y, reuse=False, verbose=True):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        inputs = tf.concat([x, y], 1)\n",
    "        fc1 = tf.layers.dense(inputs=inputs, units=256, activation=tf.nn.leaky_relu)\n",
    "        fc2 = tf.layers.dense(inputs=fc1, units=1, activation=None)\n",
    "        prob = tf.nn.sigmoid(fc2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nDiscriminator:\")\n",
    "            print(inputs)\n",
    "            print(fc1)\n",
    "            print(fc2)\n",
    "        \n",
    "    return prob, fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Discriminator input: Tensor(\"X:0\", shape=(?, 784), dtype=float32)\n",
      "Conditional variable: Tensor(\"Y:0\", shape=(?, 10), dtype=float32)\n",
      "Generator input noise: Tensor(\"Z:0\", shape=(?, 100), dtype=float32)\n",
      "\n",
      "Generator:\n",
      "Tensor(\"generator/concat:0\", shape=(?, 110), dtype=float32)\n",
      "Tensor(\"generator/dense/LeakyRelu:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"generator/dense_1/BiasAdd:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Discriminator:\n",
      "Tensor(\"discriminator/concat:0\", shape=(?, 794), dtype=float32)\n",
      "Tensor(\"discriminator/dense/LeakyRelu:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"discriminator/dense_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Discriminator input\n",
    "#X = tf.placeholder(tf.float32, shape=[None, x_train.shape[1], x_train.shape[2], 1], name='X')\n",
    "X = tf.placeholder(tf.float32, shape=[None, x_train.shape[1] * x_train.shape[2] * 1], name='X')\n",
    "\n",
    "# Generator noise input\n",
    "Z_dim = 100\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim], name='Z')\n",
    "\n",
    "# Generator conditional\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_classes], name='Y')\n",
    "\n",
    "# Print shapes\n",
    "print(\"Inputs:\")\n",
    "print(\"Discriminator input: \" + str(X))\n",
    "print(\"Conditional variable: \" + str(Y))\n",
    "print(\"Generator input noise: \" + str(Z))\n",
    "\n",
    "# Networks\n",
    "gen_sample = generator(Z, Y)\n",
    "D_real, D_logit_real = discriminator(X, Y)\n",
    "D_fake, D_logit_fake = discriminator(gen_sample, Y, reuse=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary cross entropy loss\n",
    "\\begin{equation*}\n",
    "L(\\theta) = - \\frac{1}{n} \\sum_{i=1}^n [y_i log(p_i) + (1 - y_i) log(1 - p_i)]\n",
    "\\end{equation*}\n",
    "\n",
    "- Discriminator final probability is 1 => REAL IMAGE\n",
    "- Discriminator final probability is 0 => FAKE IMAGE\n",
    "\n",
    "Log values:\n",
    "- Log(1) => Loss would be 0\n",
    "- Log(0+) => Loss would be to - ∞\n",
    "\n",
    "### Generator:\n",
    "\n",
    "Maximize D(G(z))\n",
    "\n",
    "\n",
    "### Discriminator:\n",
    "\n",
    "Maximize D(x) AND minimize D(G(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses have minus sign because I have to maximize them\n",
    "D_loss = - tf.reduce_mean( tf.log(D_real) + tf.log(1. - D_fake) )\n",
    "G_loss = - tf.reduce_mean( tf.log(D_fake) )\n",
    "\n",
    "# Optimizers\n",
    "D_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(D_loss, var_list=D_var)\n",
    "\n",
    "G_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(G_loss, var_list=G_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "1.8720952  1.5115476\n",
      "0.24303772  3.7577546\n",
      "0.02867467  5.0388317\n",
      "0.025080912  6.4115386\n",
      "Epoch 2\n",
      "0.005657221  7.28741\n",
      "0.033297196  7.825013\n",
      "0.031922825  10.013494\n",
      "0.09643358  4.3539276\n",
      "Epoch 3\n",
      "0.07344897  4.9087095\n",
      "0.055705197  5.294508\n",
      "0.07022498  7.518651\n",
      "0.01443007  6.374817\n",
      "Epoch 4\n",
      "0.031886935  6.5571027\n",
      "0.057730053  6.112449\n",
      "0.061156906  5.5489893\n",
      "0.062262736  5.3606377\n",
      "Epoch 5\n",
      "0.068884835  6.351197\n",
      "0.106538504  6.016008\n",
      "0.098894  4.410555\n",
      "0.118423685  5.106097\n",
      "Epoch 6\n",
      "0.03386496  6.036833\n",
      "0.06753452  5.511444\n",
      "0.112279475  4.7947836\n",
      "0.1124495  4.737192\n",
      "Epoch 7\n",
      "0.118285984  6.1819277\n",
      "0.09526998  4.505378\n",
      "0.04071022  5.3517876\n",
      "0.12277332  5.825102\n",
      "Epoch 8\n",
      "0.18729207  5.791994\n",
      "0.12948722  5.1236544\n",
      "0.10333397  4.8495197\n",
      "0.09946623  5.2916374\n",
      "Epoch 9\n",
      "0.17106828  7.1617365\n",
      "0.2784981  5.1359596\n",
      "0.117116354  5.226742\n",
      "0.100012794  4.585948\n",
      "Epoch 10\n",
      "0.3403443  7.2692957\n",
      "0.18812597  4.0537004\n",
      "0.21380067  4.456659\n",
      "0.18675426  5.5290513\n",
      "Epoch 11\n",
      "0.39628616  8.522469\n",
      "0.122006536  4.420188\n",
      "0.15632121  5.0806656\n",
      "0.23394153  4.222185\n",
      "Epoch 12\n",
      "0.22432297  5.802051\n",
      "0.28978077  3.8062353\n",
      "0.15125482  4.0732903\n",
      "0.43515196  4.3318906\n",
      "Epoch 13\n",
      "0.45866695  4.445985\n",
      "0.21142603  4.2419324\n",
      "0.24729943  4.7553134\n",
      "0.49115703  4.135827\n",
      "Epoch 14\n",
      "0.31582007  4.923927\n",
      "0.22674596  3.7453043\n",
      "0.253237  3.6179779\n",
      "0.33179945  4.0040264\n",
      "Epoch 15\n",
      "0.27871162  4.402337\n",
      "0.5145729  3.026649\n",
      "0.36680913  4.18355\n",
      "0.3565387  3.5695148\n",
      "Epoch 16\n",
      "0.40368164  3.611681\n",
      "0.35623342  3.7621558\n",
      "0.41002554  4.075431\n",
      "0.45516396  3.4797015\n",
      "Epoch 17\n",
      "0.5185968  4.4354343\n",
      "0.4204278  3.3732328\n",
      "0.42190042  3.5622828\n",
      "0.3015958  4.0923986\n",
      "Epoch 18\n",
      "0.5743346  2.6057758\n",
      "0.52333844  3.3171232\n",
      "0.44650987  3.998876\n",
      "0.42362845  3.0061374\n",
      "Epoch 19\n",
      "0.50296634  2.521531\n",
      "0.5069628  3.0075908\n",
      "0.3610037  3.2237988\n",
      "0.39106062  3.128495\n",
      "Epoch 20\n",
      "0.5482008  2.8167741\n",
      "0.46846572  2.665464\n",
      "0.38351822  2.8106885\n",
      "0.37109062  3.693007\n",
      "Epoch 21\n",
      "0.48912138  3.2106192\n",
      "0.30239117  3.0507336\n",
      "0.33160174  2.7450457\n",
      "0.3943308  3.3593304\n",
      "Epoch 22\n",
      "0.48019803  2.645451\n",
      "0.3521853  2.7273602\n",
      "0.5859464  2.8900068\n",
      "0.3520675  3.8135738\n",
      "Epoch 23\n",
      "0.49070475  2.3112211\n",
      "0.43717927  3.3296134\n",
      "0.5159031  3.341017\n",
      "0.23180825  3.2829747\n",
      "Epoch 24\n",
      "0.47112656  2.8633862\n",
      "0.41485077  3.1114616\n",
      "0.51857984  2.379685\n",
      "0.31901687  3.8549867\n",
      "Epoch 25\n",
      "0.42946994  3.3963153\n",
      "0.4491701  3.588256\n",
      "0.36229864  3.0172167\n",
      "0.3309073  3.1984591\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Epochs\n",
    "    for n in range(25):\n",
    "        print(\"Epoch \" + str(n+1))\n",
    "        \n",
    "        for i in range(len(x_train) // batch_size):\n",
    "            \n",
    "            X_tmp = np.reshape(x_train[i*batch_size:(i+1)*batch_size], (batch_size, -1))\n",
    "            #X_tmp = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            sampled_noise = sample_Z(batch_size, Z_dim)\n",
    "            one_hot_sampled = one_hot(batch_size, num_classes, y_train[i*batch_size:(i+1)*batch_size])\n",
    "            \n",
    "            _, D_loss_val = sess.run([D_optimizer, D_loss], feed_dict={X: X_tmp, \n",
    "                                                                       Y: one_hot_sampled,\n",
    "                                                                       Z: sampled_noise})\n",
    "\n",
    "            _, G_loss_val = sess.run([G_optimizer, G_loss], feed_dict={Y: one_hot_sampled,\n",
    "                                                                       Z: sampled_noise})\n",
    "            \n",
    "            if i % 300 == 0:\n",
    "                print(str(D_loss_val) + \"  \" + str(G_loss_val))\n",
    "                save_path = saver.save(sess, \"./checkpoints/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./checkpoints/model.ckpt\")\n",
    "    \n",
    "    sampled_noise = sample_Z(1, Z_dim)\n",
    "    one_hot_sampled = one_hot(1, num_classes, [8])\n",
    "    \n",
    "    generated = sess.run(gen_sample, feed_dict={Y: one_hot_sampled, \n",
    "                                                Z: sampled_noise})\n",
    "    img_generated = np.reshape(generated, (28, 28))\n",
    "    \n",
    "    plt.imshow(img_generated)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
